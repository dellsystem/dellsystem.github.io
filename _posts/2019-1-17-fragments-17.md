---
title: There's a storm coming
layout: fragment
description: "The 2008 financial crisis showed us what happens when your models are incomplete. Tech companies have a similar problem, but with class struggle."
---

A few days ago, I wrote about the tendency for startups to either die young, or to [live long enough to become the villain](/posts/fragments-13). They may start with good intentions and an underdog mentality (trying to "disrupt" the corrupt incumbents in the field), but as they grow, they become vulnerable to the same tendencies that affect any powerful corporation. They become every bit as villanous as what they were trying to disrupt, purely because they didn't grasp at the root of _why_ the incumbents were the way they were.

Clever technology alone does not render you immune from potentially malevolent corporate pressures. Sometimes the problem lies in the corporate form itself, and the way it's entwined with the incentive structures of an increasingly financialised economy. When a startup grows bigger and more powerful, and starts having a noticeable impact on the world - on labour markets, or housing, or even the way [people make sense of the world](https://www.nytimes.com/2018/03/10/opinion/sunday/youtube-politics-radical.html) - its responsibilities change. It's no longer the underdog, and if it doesn't want to become the villain, it'll have to adjust its model to account for the world it's helped create. It'll have to shift from a static way of viewing the world to a more dynamic one.

***

I recently read [Diary of a Very Bad Year: Confessions of an Anonymous Hedge Fund Manager](https://www.goodreads.com/book/show/6969460-diary-of-a-very-bad-year), an n+1 book featuring a series of anonymous interviews about the 2008 financial crisis. It's a fascinating read, and I highly recommend it (you can find some excerpts [here](https://nplusonemag.com/issue-7/politics/anonymous-hedge-fund-manager-i), and I've also saved some of my favourite quotes in [Bookmarker](http://bookmarker.dellsystem.me/book/diary-of-a-very-bad-year)). One comment that really struck me was about "black boxes", i.e., statistical models that were being increasingly used in the financial industry for trading:

> we had a loss over the course of three days that was like a ten-sigma event, meaning, you know, it should never happen based on the statistical models that underlie it. Because the model doesn’t assume that everybody else is trading the same model as you are. So that’s sort of like a meta-model factor. The model doesn’t know that there are other black boxes out there. (p.14)

Now, these models were theoretically cleverer than any human, because they could track a lot of variables and thus evaluate functions too complex for a human being. But they were also dumb: they couldn't account for any variables that the humans creating the models hadn't explicitly put in. Specifically, these models couldn't account for the fact that _everyone else was now using these models_. They weren't designed to handle recursive variables, like how popular that model would become, because how could you even simulate that? That's way too meta.

But that turned out to be a hugely important variable. There was one major factor undergirding everything, but nobody thought to account for it because they didnt know it was a possibility. Like, their imaginations just didn't stretch that far. No one in their finance classes had ever told them to prepare for a future where everybody was using the same model, generating huge amounts of systemic risk in the process. It was a possibility that most had never considered, or if they had, they just didn't care.

And why would they? It was the golden ages of finance. Money was easy; Wall Street was booming. And anyway, who was going to stop them?

***

When I read about tech companies' business models today, sometimes I get a whiff of that same sort of hubris. It's when someone who is currently on top assumes that the initial starting conditions - the ones that led to their success - will continue forever.

In a way, it makes sense; every startup runs on assumptions that are functionally invisible, purely because they're so ingrained in the prevailing culture. You wouldn't mention in your pitch deck that your business model relies on a working electricity grid, or roads, or the sun, or the absence of a global revolution which ends with all the founders being guillotined. These assumptions are not within the purview of a startup business model, which usually assumes a static (or at least reasonably stable) socioeconomic terrain.

But what happens if this assumption is no longer valid? What happens if the introduction of that very business model, on a large enough scale, itself affects the political-economic consensus?

Companies like Uber and Amazon and Postmates take for granted the existence of a docile workforce, willing to do menial tasks in exchange for not much money and little in the way of benefits. It's a part of their business model, and maybe even the most significant part, seeing as robots haven't fully replaced all these inconvenient human workers yet. In fact, these companies' valuations are _predicated_ on the continued acquiescence of workers - on their acceptance of whatever shitty employment conditions management decides is better for their bottom line. All their business models just assume that this dystopian neoliberal hellscape we live in will keep going on forever.

It reminds me of the way banks behaved in the lead-up to the financial crisis: as if these golden ages would stretch on to infinity, or at least, long enough that everyone could still make a ton of money. As if there could not be any possible _repercussions_. As if rising levels of inequality were just fine, actually, and nothing could go wrong. As if there's no link between the growing homeless population in the Bay Area and the gaudy mansions of all the newly monied tech superstars.

And so Uber is going to become UberWorks - the staffing agency mediating every potential employment relationship (now Uberified, so workers don't have employee benefits or protections). [WeWork](https://www.bloomberg.com/opinion/articles/2019-01-08/wework-gets-a-visit-from-financial-reality) is going to become the horizontal layer underpinning every fucking aspect of our existence, making a hefty profit in the process. Amazon's going to keep being Amazon. And they think it will just keep happening? People won't resist? There are no systemic risks?

I guess it makes sense if you're used to this particular neoliberal consensus. It's the end of history: there are no alternatives to financialised, globalised capitalism. Class struggle is a thing of the past, and if working people aren't happy with their economic conditions, they should just lean into meritocracy & learn to code. You don't consider "the resurgence of class politics" as a risk factor worth adding to your quarterly reports.

But workers are already starting to organise. And electorally, we're seeing a wave of left-wing politicians gaining popularity, especially in the US. Who knows how much longer these "golden ages" (for capital) will last.

***

The title of this post comes from a scene in _The Dark Knight Rises_. If you couldn't already tell from my blog post about [becoming the villain](/posts/fragments-13) I'm a huge fan of Christopher Nolan's Batman films, even if they have a very reactionary political line ([David Graeber](https://thenewinquiry.com/super-position/) has a wonderful essay over at _The New Inquiry_ dissecting the extent to which _The Dark Knight Rises_ was anti-Occupy Wall Street propaganda). The titular quote is said by Selina Kyle to Bruce Wayne, while they're at a fairly lavish-looking banquet:

> There's a storm coming, Mr. Wayne. You and your friends better batten down the hatches, because when it hits, you're all going to wonder how you ever thought you could live so large and leave so little for the rest of us.

Even though the film ultimately tries to discredit this perspective (Selina later takes up with Bruce Wayne and hangs out with him at cafes in France, presumably having abandoned her previous desire to overthrow capitalism), I still really like this quote, and I think about it a lot in the context of tech companies.

For example, Jeff Bezos and (soon to be ex-) wife have a combined net worth of over $100 billion, which, even if it's not exactly surplus value (since it's all stock market valuations, and thus essentially made-up numbers - the topic of a future blog post), is still premised on the continued exploitation of the workers in his empire, as demonstrated to the satisfaction of potential shareholders. Do they think this system is stable? Do they think they can keep doing this forever, maybe chucking a few paltry millions at charity now and then?

Of course, this phenomenon isn't isolated to the tech industry, either: you see extreme wealth alongside blistering poverty in many other parts of the economy, in these dark days of late capitalism. It's just that tech companies have a special knack for the "[winners take all](http://www.anand.ly/winners-take-all/)" model, achieved by hoarding technological innovation that should belong to us all in common, and using it instead to concentrate wealth and power.

You can't concentrate _that_ much wealth and power without a backlash. It's already begun, I think. There's a storm coming; tech companies' greed won't have _caused_ it, but it will probably have hastened it. That is, unless they manage to update their models to account for the shifting balance of class forces. But by then, it might already be too late.
